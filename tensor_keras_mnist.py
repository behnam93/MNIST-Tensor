# -*- coding: utf-8 -*-
"""Tensor-keras-MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1197fO_XWDoXt9h18AGQBZWTMSVpydNQQ
"""

import tensorflow as tf
import numpy as np

import tensorflow_datasets

(train, test), info = tensorflow_datasets.load('mnist', split=['train','test'], as_supervised=True, with_info=True)

info

train

def normalize(image, label):
  return tf.cast(image, tf.float32) / 256 , label
train = train.map(normalize)
train

train = train.cache()

train = train.shuffle(info.splits['train'].num_examples)

train = train.batch(256)

train = train.prefetch(tf.data.experimental.AUTOTUNE)

test = test.map(normalize)
test = test.batch(256)
test = test.cache()
test = test.prefetch(tf.data.experimental.AUTOTUNE)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28,28)),
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=tf.keras.losses.
              SparseCategoricalCrossentropy(from_logits=True),metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

model.fit(train, epochs=100, validation_data=test)

model.predict(test)